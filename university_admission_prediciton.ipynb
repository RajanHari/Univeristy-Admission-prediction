{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "university_admission_prediciton.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfiyrlrcEAL2"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8g65QxlTEG7e"
      },
      "source": [
        "admission_df = pd.read_csv('Admission_predict.csv')\r\n",
        "\r\n",
        "print(admission_df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEFn7t_iEG9x"
      },
      "source": [
        "admission_df.drop('Serial No.', axis= 1, inplace = True)\r\n",
        "\r\n",
        "print(admission_df.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eHdCiswEHAi"
      },
      "source": [
        "print(admission_df.info())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV-ndddvEHCw"
      },
      "source": [
        "print(admission_df.describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20_rEnUAEVxy"
      },
      "source": [
        "Grouping based on university ratings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypMFpjskEQBa"
      },
      "source": [
        "univ_df = admission_df.groupby(by = 'University Rating').mean()\r\n",
        "print(univ_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CNQtVE8EYnS"
      },
      "source": [
        "ignoring float in cgpa column and grouping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmNdojcCEQDp"
      },
      "source": [
        "cgparange_df = admission_df.copy()\r\n",
        "cgparange_df['CGPA'] = cgparange_df['CGPA'].astype('int')\r\n",
        "print(cgparange_df.groupby(by = 'CGPA').mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fr2jafqEdjv"
      },
      "source": [
        "Histograms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0YEx7c8EQGM"
      },
      "source": [
        "admission_df.hist(column = 'CGPA', bins = 5,figsize = (5,5), color ='red')\r\n",
        "admission_df.hist(column = 'GRE Score', bins = 10,figsize = (7,7), color ='red')\r\n",
        "\r\n",
        "sns.pairplot(admission_df, x_vars = ('GRE Score','University Rating','CGPA'), y_vars = ('TOEFL Score','SOP'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0H7HKoD5Ejwv"
      },
      "source": [
        "correlation matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKL8YgKdEQIp"
      },
      "source": [
        "corr_matrix = admission_df.corr()\r\n",
        "plt.figure(figsize =(15,15))\r\n",
        "sns.heatmap(corr_matrix, annot = True)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52THFqteEq-r"
      },
      "source": [
        "X = admission_df.iloc[:,:-1]\r\n",
        "y = admission_df.iloc[:,-1]\r\n",
        "\r\n",
        "X.shape\r\n",
        "y.shape\r\n",
        "\r\n",
        "X = np.array(X)\r\n",
        "y = np.array(y)\r\n",
        "\r\n",
        "y = y.reshape(-1,1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTNJMeRpErYq"
      },
      "source": [
        "Scaling data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwQ3FJAMEtW3"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\r\n",
        "scalerx = StandardScaler()\r\n",
        "scalery = StandardScaler()\r\n",
        "X = scalerx.fit_transform(X)\r\n",
        "y = scalery.fit_transform(y)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9gRthtNEvMG"
      },
      "source": [
        "Splitting data into train and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBf3zyllExPJ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.15, random_state = 1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZClsTXiEzMm"
      },
      "source": [
        "Trainig and evaluating a linear regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMfXDwTLE1RG"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "\r\n",
        "LinerRegression_model = LinearRegression()\r\n",
        "LinerRegression_model.fit(X_train, y_train)\r\n",
        "\r\n",
        "accuracy_LinearRegression = LinerRegression_model.score(X_test, y_test)\r\n",
        "print(accuracy_LinearRegression)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQ8G8c0QE286"
      },
      "source": [
        "Training and evaluating an ANN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VttoUdKsE4uo"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "\r\n",
        "ANN_model = tf.keras.models.Sequential()\r\n",
        "ANN_model.add(tf.keras.layers.Dense(50, input_dim = 7, activation='relu'))\r\n",
        "\r\n",
        "ANN_model.add(tf.keras.layers.Dense(150, activation='relu'))\r\n",
        "tf.keras.layers.Dropout(0.5)\r\n",
        "\r\n",
        "ANN_model.add(tf.keras.layers.Dense(150, activation='relu'))\r\n",
        "tf.keras.layers.Dropout(0.5)\r\n",
        "\r\n",
        "ANN_model.add(tf.keras.layers.Dense(50, activation='linear'))\r\n",
        "ANN_model.add(tf.keras.layers.Dense(1))\r\n",
        "\r\n",
        "ANN_model.compile(loss = 'mse', optimizer = 'adam')\r\n",
        "ANN_model.summary()\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "epochs_hist = ANN_model.fit(X_train, y_train, epochs = 100, batch_size = 20)\r\n",
        "y_pred_ann = ANN_model.predict(X_test)\r\n",
        "print(y_pred_ann)\r\n",
        "\r\n",
        "\r\n",
        "result = ANN_model.evaluate(X_test, y_test)\r\n",
        "accuracy_ANN = 1-result\r\n",
        "\r\n",
        "print(\"Accuracy :{}\".format(accuracy_ANN))\r\n",
        "\r\n",
        "epochs_hist.history.keys()\r\n",
        "\r\n",
        "plt.plot(epochs_hist.history['loss'])\r\n",
        "plt.title('model loss during training')\r\n",
        "plt.xlabel('epochs')\r\n",
        "plt.ylabel('training loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujwslvFgE7RS"
      },
      "source": [
        "Training and evaluating decision trees and random forest regressors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q3S0HHYE9JQ"
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\r\n",
        "\r\n",
        "DecisionTree_model = DecisionTreeRegressor()\r\n",
        "DecisionTree_model.fit(X_train, y_train)\r\n",
        "\r\n",
        "accuracy_DecisionTree = DecisionTree_model.score(X_test, y_test)\r\n",
        "print(accuracy_DecisionTree)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShSBACL4FCbs"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\r\n",
        "\r\n",
        "RandomForest_model = RandomForestRegressor(n_estimators =100, max_depth =10)\r\n",
        "RandomForest_model.fit(X_train, y_train)\r\n",
        "\r\n",
        "accuracy_RandomForest = RandomForest_model.score(X_test, y_test) \r\n",
        "print(accuracy_RandomForest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3tr7sPDFESj"
      },
      "source": [
        "Calculating regression model KPIs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Utl4rw1FO66"
      },
      "source": [
        "y_pred = LinerRegression_model.predict(X_test)\r\n",
        "\r\n",
        "plt.plot(y_test, y_pred, '^', color = 'r')\r\n",
        "\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "scaler = StandardScaler()\r\n",
        "scaler.fit(y_pred)\r\n",
        "\r\n",
        "y_pred_orig = scaler.inverse_transform(y_pred) \r\n",
        "\r\n",
        "\" we wanna plot in the original units, not in the scaled units\"\r\n",
        "\r\n",
        "y_test_orig = scaler.inverse_transform(y_test)\r\n",
        "\r\n",
        "plt.plot(y_test_orig, y_pred_orig, '^', color = 'r')\r\n",
        "\r\n",
        "\" we get chance of admit with values between  and 1 \""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Bv_N_DvFSbt"
      },
      "source": [
        "k = X_test.shape[1]\r\n",
        "n = len(X_test)\r\n",
        "print(k)\r\n",
        "print(n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8OQhb0EFVmA"
      },
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\r\n",
        "from math import sqrt\r\n",
        "\r\n",
        "RMSE = float(format(np.sqrt(mean_squared_error(y_test_orig, y_pred_orig)), '.3f')) \r\n",
        "MSE = mean_squared_error(y_test_orig, y_pred_orig)\r\n",
        "MAE = mean_absolute_error(y_test_orig, y_pred_orig)\r\n",
        "r2 = r2_score(y_test_orig, y_pred_orig)\r\n",
        "\r\n",
        "adj_r2 = 1-(1-r2)*(n-1)/(n-k-1)\r\n",
        "\r\n",
        "print('RMSE =', RMSE,'\\nMSE =', MSE,'\\nMAE =', MAE,'\\nR2 =', r2,'\\nAdjusted R2 =', adj_r2)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}